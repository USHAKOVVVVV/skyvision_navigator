{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c44b92",
   "metadata": {},
   "source": [
    "# –¢–µ—Å—Ç–∏–∫–∏ –ø–µ—Å—Ç–∏–∫–∏ #\n",
    "–¢–µ—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å –Å–ª—ë12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a35440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bab4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov12n.yaml')\n",
    "\n",
    "# n - –º–∏–Ω–∏–º–∫—É–º\n",
    "# s\n",
    "# m\n",
    "# l\n",
    "# x = –º–∞–∫—Å–∏–º—É–º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410ca9b",
   "metadata": {},
   "source": [
    "–°–º–æ—Ç—Ä–∏–º –¥–æ—Å—Ç—É–ø–Ω–æ –ª–∏ CPU\n",
    "\n",
    "–ï—Å–ª–∏ –Ω–µ—Ç, —Ç–æ –Ω—É–∂–Ω–æ –±—É—Ç –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –ø–æ—Å—Ç–∞–≤–∏—Ç—å device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c5ee3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9604ddf",
   "metadata": {},
   "source": [
    "__–¢—É—Ç–æ—Ä —á–µ –≤—ã–±—Ä–∞—Ç—å –ø—Ä–∏ –∫–∞–∫–æ–º –∂–µ–ª–µ–∑–Ω—è–∫–µ__\n",
    "\n",
    "* batch (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π)\n",
    "    * cpu: 2-4\n",
    "    * 8gb: 8-16\n",
    "    * 12gb: 16-24\n",
    "\n",
    "* workers\n",
    "    * cpu: 1(\n",
    "    * 8gb: 4-6\n",
    "    * 12gb: 6-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "300327b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.214 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.63  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov12n.yaml, data=data.yaml, epochs=20, time=None, patience=15, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=2, project=None, name=yolov12s_gpu_simple_2, exist_ok=True, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.005, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.1, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\yolov12s_gpu_simple_2\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      2368  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2, 1, 2]          \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1      9344  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2, 1, 4]          \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  2    174720  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  2    677120  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n",
      " 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 21        [14, 17, 20]  1    431647  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "YOLOv12n summary: 497 layers, 2,520,639 parameters, 2,520,623 gradients, 6.0 GFLOPs\n",
      "\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1650 GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\–≤—Å—è–∫–∞—è —Ö—É–π–Ω—è –ò–≥–Ω–∞—Ç–∞\\SkyVision\\train\\labels.cache... 15243 images, 920 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15243/15243 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\2066_jpg.rf.8f076a7436af9b8965a29ee2c70173c9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\2066_jpg.rf.e39c8475a83e2b097294bdb11c6b60e3.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\7277_jpg.rf.3491f767bd90d1c878806ae89cda07cd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\7277_jpg.rf.6f3233ffbe7fe994914f09ce509657dc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Kharkiv_2022_A_1_R1C5_10000_10500_3500_4000_jpg.rf.633047caf71fc13a205649024ab5ff0e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Kharkiv_2022_A_1_R1C5_11500_12000_5000_5500_jpg.rf.b97a7be0164294c358af94b1850c06d6.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_1000_1500_2000_2500_jpg.rf.844984fc01e8e5ff754bdacb89aa5063.jpg: 11 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_1000_1500_7000_7500_jpg.rf.cb19ace54fa7d037ec4f2b88cf1a277c.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_1000_1500_9000_9500_jpg.rf.8f4afb07362b9eabb114b8fa6f59a7cc.jpg: 12 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_1000_1500_9500_10000_jpg.rf.ca836179a40f9c3bb7c8b3ca57122d37.jpg: 12 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_10500_11000_11500_12000_jpg.rf.33a1072ad36cf872a299bcaa64a158d4.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_V2_R2C4_500_1000_12000_12500_jpg.rf.97a02ca5ecf1e30556acb18233319dcb.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\–≤—Å—è–∫–∞—è —Ö—É–π–Ω—è –ò–≥–Ω–∞—Ç–∞\\SkyVision\\valid\\labels.cache... 3122 images, 215 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3122/3122 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\  \\SkyVision\\valid\\images\\2318_jpg.rf.b6a36269cb2eeac0825210a49cb326c1.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\yolov12s_gpu_simple_2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.005, momentum=0.937) with parameter groups 121 weight(decay=0.0), 128 weight(decay=0.0005), 127 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\yolov12s_gpu_simple_2\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      1.69G      2.208      2.821       2.44          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [23:31<00:00,  5.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:40<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.526      0.255      0.228      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      1.74G      1.593      2.081      1.729          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [22:57<00:00,  5.53it/s] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:49<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.379      0.341      0.304      0.191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      1.75G      1.462      1.867      1.605         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [22:08<00:00,  5.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:38<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.352      0.422      0.319      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      1.82G      1.357      1.724       1.52          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [21:26<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:37<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.501      0.466      0.411      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      1.72G      1.298      1.626      1.468          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [22:23<00:00,  5.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:37<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.545      0.474      0.483       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      1.82G      1.249      1.547      1.434         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [21:27<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:40<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.538      0.496      0.503      0.324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      1.77G       1.23      1.509      1.411          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [23:37<00:00,  5.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:42<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.582      0.519      0.519      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      1.75G      1.198      1.445      1.384         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [21:55<00:00,  5.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:48<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.632      0.545      0.566      0.394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20       1.8G      1.175      1.406      1.371          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [22:30<00:00,  5.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:36<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.592      0.544      0.545      0.364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      1.73G      1.153       1.37      1.351         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [21:24<00:00,  5.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:36<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802       0.62      0.545      0.569        0.4\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      1.66G      1.147      1.492      1.449          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [21:14<00:00,  5.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:37<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.566      0.513      0.521      0.379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      1.72G      1.123      1.435      1.427          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [21:13<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:36<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.576      0.548       0.56      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      1.67G      1.098      1.355      1.401          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [22:12<00:00,  5.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:36<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.628      0.548      0.597      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      1.72G       1.08      1.326      1.385         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [21:15<00:00,  5.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:36<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.615      0.558      0.581      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      1.72G      1.069      1.293      1.376          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [21:16<00:00,  5.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:36<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.661      0.565      0.625       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      1.72G      1.047      1.253       1.36          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [21:14<00:00,  5.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:36<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802       0.68      0.576      0.627      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      1.72G       1.02      1.205      1.338          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [21:27<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:48<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.719      0.582      0.645      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      1.65G      1.003      1.197      1.326          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [23:16<00:00,  5.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:48<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.689      0.594       0.65      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      1.71G     0.9913      1.149      1.315          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [21:13<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:42<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.695      0.595      0.659        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      1.72G     0.9737      1.119      1.306          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7622/7622 [22:05<00:00,  5.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:36<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.712      0.619      0.677      0.509\n",
      "\n",
      "20 epochs completed in 7.900 hours.\n",
      "Optimizer stripped from runs\\detect\\yolov12s_gpu_simple_2\\weights\\last.pt, 5.4MB\n",
      "Optimizer stripped from runs\\detect\\yolov12s_gpu_simple_2\\weights\\best.pt, 5.4MB\n",
      "\n",
      "Validating runs\\detect\\yolov12s_gpu_simple_2\\weights\\best.pt...\n",
      "Ultralytics 8.3.63  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "YOLOv12n summary (fused): 376 layers, 2,509,319 parameters, 0 gradients, 5.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [01:28<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.712      0.618      0.676      0.509\n",
      "              building       1791      26349      0.757      0.383      0.551      0.326\n",
      "                 field        792       1042      0.769      0.772      0.818      0.694\n",
      "                forest        699        859      0.832      0.743      0.801      0.649\n",
      "                  lake        203        358      0.682       0.62      0.642      0.477\n",
      "                  road        167        194      0.522      0.573      0.571      0.398\n",
      "Speed: 0.4ms preprocess, 21.1ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\yolov12s_gpu_simple_2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=20,          # –≠–ø–æ—Ö–∏\n",
    "    \n",
    "    imgsz=640, # –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω—å–∫–∏ —Å—Ç–∞–≤–∏–º 640, —Ç.–∫. –≤ —ç—Ç–æ–º —Ñ–æ—Ä–º–∞—Ç–µ —Ä–∞–∑–º–µ—á–∞–µ–º\n",
    "    \n",
    "    batch=2,            # –ü–æ —Å–∫–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–µ–∫ –±–µ—Ä–µ–º –∑–∞ –ø—Ä–æ–≥–æ–Ω\n",
    "    \n",
    "    patience=15,    #–¢–µ—Ä–ø–µ–Ω–∏–µ, —Ö–∑ —á–µ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç ?\n",
    "\n",
    "    device='cuda',      # –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU, –µ—Å–ª–∏ –Ω–µ—Ç –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—ã, –µ—Å–ª–∏ –µ—Å—Ç—å, —Ç–æ —Å—Ç–∞–≤–∏–º 'cuda'\n",
    "\n",
    "    workers=2,          # –ú–∏–Ω–∏–º—É–º workers\n",
    "    \n",
    "    lr0=0.005,   # –õ–µ—Ä–Ω–∏–Ω–≥ —Ä—ç–π—Ç ?\n",
    "\n",
    "    optimizer='Adam',   # Adam - –ª–µ–≥–∫–∏–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä, AdamW - –ñ–µ—Å—Ç—á–µ\n",
    "\n",
    "    # weight_decay = 0.0005,   # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è ?\n",
    "    \n",
    "    name='yolov12s_gpu_simple_2',\n",
    "    \n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762692e5",
   "metadata": {},
   "source": [
    "–¢–µ—Å—Ç–∏–º —á–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dec57047",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'runs/detect/yolov12s_gpu_simple_2/weights/best.pt'\n",
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26378980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–ª–∞—Å—Å—ã: {0: 'building', 1: 'field', 2: 'forest', 3: 'lake', 4: 'road'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"–ö–ª–∞—Å—Å—ã: {model.names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec7fc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05fe8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('runs/detect/train/results.png'):\n",
    "    display(Image(filename='runs/detect/train/results.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28ea4ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.63  Python-3.11.9 torch-2.5.1+cu121 CPU (AMD Ryzen 5 2600 Six-Core Processor)\n",
      "YOLOv12n summary (fused): 376 layers, 2,509,319 parameters, 0 gradients, 5.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\–≤—Å—è–∫–∞—è —Ö—É–π–Ω—è –ò–≥–Ω–∞—Ç–∞\\SkyVision\\test\\labels.cache... 1579 images, 124 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1579/1579 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\  \\SkyVision\\test\\images\\2664_jpg.rf.e165d9af80c1d4d370593d2b5b5fa34b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\  \\SkyVision\\test\\images\\Kharkiv_2022_A_1_R1C6_2000_2500_5000_5500_jpg.rf.416898acb3bcccea2602a36beed5b08e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\  \\SkyVision\\test\\images\\Tripoli_2022_R3C2_1000_1500_13500_14000_jpg.rf.4a303c5c4fabd5987b3701fe35c81e92.jpg: 5 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [03:21<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1579      13715      0.814      0.611      0.725      0.584\n",
      "              building        884      12393      0.817      0.389      0.601      0.408\n",
      "                 field        421        566       0.88      0.753      0.846      0.753\n",
      "                forest        371        446       0.95       0.76       0.86      0.743\n",
      "                  lake        107        201       0.68      0.592      0.643      0.505\n",
      "                  road         94        109      0.744       0.56      0.674      0.514\n",
      "Speed: 1.4ms preprocess, 103.6ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val4\u001b[0m\n",
      "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏:\n",
      "mAP50: 0.725\n"
     ]
    }
   ],
   "source": [
    "# –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "results = model.val(\n",
    "    data='data.yaml',\n",
    "    split='test',    # –∏—Å–ø–æ–ª—å–∑—É–µ–º –¢–ï–°–¢–û–í–´–ï –¥–∞–Ω–Ω—ã–µ\n",
    "    conf=0.25, # —É—Ä–æ–≤–µ–Ω—å –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏\n",
    "    iou=0.3, #–º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "print(f\"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏:\")\n",
    "print(f\"mAP50: {results.box.map50:.3f}\")\n",
    "\n",
    "# print(results.box)\n",
    "\n",
    "# –ï—Å–ª–∏ mAP50 < 0.6 ‚Üí –Ω—É–∂–Ω–æ —É–ª—É—á—à–∞—Ç—å –º–æ–¥–µ–ª—å\n",
    "# –ï—Å–ª–∏ mAP50 > 0.8 ‚Üí –æ—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9189a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('–ú–æ–¥–µ–ª—é—Å–∏/test_yolov12n_gpu_1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab90c6d",
   "metadata": {},
   "source": [
    "–¢–µ—Å—Ç—ã –º–æ–¥–µ–ª–µ–π:\n",
    "\n",
    "cpu yolov10n - p: 1        r: 0.5       map50: 0.75       map50-95: 0.56\n",
    "\n",
    "gpu yolob12n - p:0.81   r:0.61  map50:72    map50-95:0.58   103.6ms inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875c15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 buildings, 20.0ms\n",
      "Speed: 17.0ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–π —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏: 0.361 —Å–µ–∫—É–Ω–¥\n"
     ]
    }
   ],
   "source": [
    "# –¢–µ—Å—Ç —Ä–∞–Ω–¥–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "model = YOLO('–ú–æ–¥–µ–ª—é—Å–∏/test_yolov12n_gpu_1.pt')\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
    "image_path = '–ú–æ–¥–µ–ª—é—Å–∏/just_Ignat.PNG'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "start_time = time.time()\n",
    "results = model.predict(image)  # –∏–ª–∏ model.predict(image)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–π —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏: {end_time - start_time:.3f} —Å–µ–∫—É–Ω–¥\")\n",
    "\n",
    "# –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "for r in results:\n",
    "    im_array = r.plot()  # —Ä–∏—Å—É–µ–º bbox –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏\n",
    "    cv2.imshow('Result', im_array)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "199f2728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...\n",
      "\n",
      "image 1/1 d:\\  \\SkyVision\\\\image.PNG: 512x640 (no detections), 47.0ms\n",
      "Speed: 3.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.133 —Å–µ–∫—É–Ω–¥\n",
      "üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: –ú–æ–¥–µ–ª—é—Å–∏\\image_result.jpg\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "model = YOLO('–ú–æ–¥–µ–ª—é—Å–∏/test_yolov12n_gpu_1.pt')\n",
    "image_path = '–ú–æ–¥–µ–ª—é—Å–∏/image.PNG'\n",
    "\n",
    "print(\"üöÄ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...\")\n",
    "start_time = time.time()\n",
    "\n",
    "results = model(image_path)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {end_time - start_time:.3f} —Å–µ–∫—É–Ω–¥\")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ç—É –∂–µ –ø–∞–ø–∫—É\n",
    "output_dir = os.path.dirname(image_path)  # –ø–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ\n",
    "output_path = os.path.join(output_dir, 'image_result.jpg')\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –¥–µ—Ç–µ–∫—Ü–∏—è–º–∏\n",
    "for r in results:\n",
    "    r.save(filename=output_path)\n",
    "\n",
    "print(f\"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76589f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import cv2\n",
    "for r in results:\n",
    "    im_array = r.plot()  # —Ä–∏—Å—É–µ–º bbox –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏\n",
    "    cv2.imshow('Result', im_array)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
