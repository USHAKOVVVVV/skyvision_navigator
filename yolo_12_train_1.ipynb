{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c44b92",
   "metadata": {},
   "source": [
    "# Тестики пестики #\n",
    "Тестовая модель Ёлё12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a35440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bab4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov12n.yaml')\n",
    "\n",
    "# n - минимкум\n",
    "# s\n",
    "# m\n",
    "# l\n",
    "# x = максимум"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410ca9b",
   "metadata": {},
   "source": [
    "Смотрим доступно ли CPU\n",
    "\n",
    "Если нет, то нужно бут при обучении поставить device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c5ee3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9604ddf",
   "metadata": {},
   "source": [
    "__Тутор че выбрать при каком железняке__\n",
    "\n",
    "* batch (количество батчей)\n",
    "    * cpu: 2-4\n",
    "    * 8gb: 8-16\n",
    "    * 12gb: 16-24\n",
    "\n",
    "* workers\n",
    "    * cpu: 1(\n",
    "    * 8gb: 4-6\n",
    "    * 12gb: 6-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "300327b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.214 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.63  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov12n.yaml, data=data.yaml, epochs=20, time=None, patience=15, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=2, project=None, name=yolov12s_gpu_simple_2, exist_ok=True, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.005, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.1, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\yolov12s_gpu_simple_2\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      2368  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2, 1, 2]          \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1      9344  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2, 1, 4]          \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  2    174720  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  2    677120  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n",
      " 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 21        [14, 17, 20]  1    431647  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "YOLOv12n summary: 497 layers, 2,520,639 parameters, 2,520,623 gradients, 6.0 GFLOPs\n",
      "\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1650 GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\всякая хуйня Игната\\SkyVision\\train\\labels.cache... 15243 images, 920 backgrounds, 0 corrupt: 100%|██████████| 15243/15243 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\2066_jpg.rf.8f076a7436af9b8965a29ee2c70173c9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\2066_jpg.rf.e39c8475a83e2b097294bdb11c6b60e3.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\7277_jpg.rf.3491f767bd90d1c878806ae89cda07cd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\7277_jpg.rf.6f3233ffbe7fe994914f09ce509657dc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Kharkiv_2022_A_1_R1C5_10000_10500_3500_4000_jpg.rf.633047caf71fc13a205649024ab5ff0e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Kharkiv_2022_A_1_R1C5_11500_12000_5000_5500_jpg.rf.b97a7be0164294c358af94b1850c06d6.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_1000_1500_2000_2500_jpg.rf.844984fc01e8e5ff754bdacb89aa5063.jpg: 11 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_1000_1500_7000_7500_jpg.rf.cb19ace54fa7d037ec4f2b88cf1a277c.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_1000_1500_9000_9500_jpg.rf.8f4afb07362b9eabb114b8fa6f59a7cc.jpg: 12 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_1000_1500_9500_10000_jpg.rf.ca836179a40f9c3bb7c8b3ca57122d37.jpg: 12 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_10500_11000_11500_12000_jpg.rf.33a1072ad36cf872a299bcaa64a158d4.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_V2_R2C4_500_1000_12000_12500_jpg.rf.97a02ca5ecf1e30556acb18233319dcb.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\всякая хуйня Игната\\SkyVision\\valid\\labels.cache... 3122 images, 215 backgrounds, 0 corrupt: 100%|██████████| 3122/3122 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\  \\SkyVision\\valid\\images\\2318_jpg.rf.b6a36269cb2eeac0825210a49cb326c1.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\yolov12s_gpu_simple_2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.005, momentum=0.937) with parameter groups 121 weight(decay=0.0), 128 weight(decay=0.0005), 127 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\yolov12s_gpu_simple_2\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      1.69G      2.208      2.821       2.44          8        640: 100%|██████████| 7622/7622 [23:31<00:00,  5.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:40<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.526      0.255      0.228      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      1.74G      1.593      2.081      1.729          8        640: 100%|██████████| 7622/7622 [22:57<00:00,  5.53it/s] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:49<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.379      0.341      0.304      0.191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      1.75G      1.462      1.867      1.605         12        640: 100%|██████████| 7622/7622 [22:08<00:00,  5.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:38<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.352      0.422      0.319      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      1.82G      1.357      1.724       1.52          2        640: 100%|██████████| 7622/7622 [21:26<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:37<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.501      0.466      0.411      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      1.72G      1.298      1.626      1.468          5        640: 100%|██████████| 7622/7622 [22:23<00:00,  5.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:37<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.545      0.474      0.483       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      1.82G      1.249      1.547      1.434         18        640: 100%|██████████| 7622/7622 [21:27<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:40<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.538      0.496      0.503      0.324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      1.77G       1.23      1.509      1.411          6        640: 100%|██████████| 7622/7622 [23:37<00:00,  5.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:42<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.582      0.519      0.519      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      1.75G      1.198      1.445      1.384         10        640: 100%|██████████| 7622/7622 [21:55<00:00,  5.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:48<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.632      0.545      0.566      0.394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20       1.8G      1.175      1.406      1.371          4        640: 100%|██████████| 7622/7622 [22:30<00:00,  5.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:36<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.592      0.544      0.545      0.364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      1.73G      1.153       1.37      1.351         23        640: 100%|██████████| 7622/7622 [21:24<00:00,  5.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:36<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802       0.62      0.545      0.569        0.4\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      1.66G      1.147      1.492      1.449          1        640: 100%|██████████| 7622/7622 [21:14<00:00,  5.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:37<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.566      0.513      0.521      0.379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      1.72G      1.123      1.435      1.427          0        640: 100%|██████████| 7622/7622 [21:13<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:36<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.576      0.548       0.56      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      1.67G      1.098      1.355      1.401          2        640: 100%|██████████| 7622/7622 [22:12<00:00,  5.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:36<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.628      0.548      0.597      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      1.72G       1.08      1.326      1.385         11        640: 100%|██████████| 7622/7622 [21:15<00:00,  5.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:36<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.615      0.558      0.581      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      1.72G      1.069      1.293      1.376          1        640: 100%|██████████| 7622/7622 [21:16<00:00,  5.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:36<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.661      0.565      0.625       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      1.72G      1.047      1.253       1.36          2        640: 100%|██████████| 7622/7622 [21:14<00:00,  5.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:36<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802       0.68      0.576      0.627      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      1.72G       1.02      1.205      1.338          0        640: 100%|██████████| 7622/7622 [21:27<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:48<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.719      0.582      0.645      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      1.65G      1.003      1.197      1.326          0        640: 100%|██████████| 7622/7622 [23:16<00:00,  5.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:48<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.689      0.594       0.65      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      1.71G     0.9913      1.149      1.315          2        640: 100%|██████████| 7622/7622 [21:13<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:42<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.695      0.595      0.659        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      1.72G     0.9737      1.119      1.306          2        640: 100%|██████████| 7622/7622 [22:05<00:00,  5.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:36<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.712      0.619      0.677      0.509\n",
      "\n",
      "20 epochs completed in 7.900 hours.\n",
      "Optimizer stripped from runs\\detect\\yolov12s_gpu_simple_2\\weights\\last.pt, 5.4MB\n",
      "Optimizer stripped from runs\\detect\\yolov12s_gpu_simple_2\\weights\\best.pt, 5.4MB\n",
      "\n",
      "Validating runs\\detect\\yolov12s_gpu_simple_2\\weights\\best.pt...\n",
      "Ultralytics 8.3.63  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "YOLOv12n summary (fused): 376 layers, 2,509,319 parameters, 0 gradients, 5.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 781/781 [01:28<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3122      28802      0.712      0.618      0.676      0.509\n",
      "              building       1791      26349      0.757      0.383      0.551      0.326\n",
      "                 field        792       1042      0.769      0.772      0.818      0.694\n",
      "                forest        699        859      0.832      0.743      0.801      0.649\n",
      "                  lake        203        358      0.682       0.62      0.642      0.477\n",
      "                  road        167        194      0.522      0.573      0.571      0.398\n",
      "Speed: 0.4ms preprocess, 21.1ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\yolov12s_gpu_simple_2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=20,          # Эпохи\n",
    "    \n",
    "    imgsz=640, # Размер изображеньки ставим 640, т.к. в этом формате размечаем\n",
    "    \n",
    "    batch=2,            # По скок изображенек берем за прогон\n",
    "    \n",
    "    patience=15,    #Терпение, хз че это значит ?\n",
    "\n",
    "    device='cuda',      # Используем CPU, если нет видеокарты, если есть, то ставим 'cuda'\n",
    "\n",
    "    workers=2,          # Минимум workers\n",
    "    \n",
    "    lr0=0.005,   # Лернинг рэйт ?\n",
    "\n",
    "    optimizer='Adam',   # Adam - легкий оптимизатор, AdamW - Жестче\n",
    "\n",
    "    # weight_decay = 0.0005,   # Регуляризация ?\n",
    "    \n",
    "    name='yolov12s_gpu_simple_2',\n",
    "    \n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762692e5",
   "metadata": {},
   "source": [
    "Тестим че получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dec57047",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'runs/detect/yolov12s_gpu_simple_2/weights/best.pt'\n",
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26378980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классы: {0: 'building', 1: 'field', 2: 'forest', 3: 'lake', 4: 'road'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Классы: {model.names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec7fc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05fe8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('runs/detect/train/results.png'):\n",
    "    display(Image(filename='runs/detect/train/results.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28ea4ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.63  Python-3.11.9 torch-2.5.1+cu121 CPU (AMD Ryzen 5 2600 Six-Core Processor)\n",
      "YOLOv12n summary (fused): 376 layers, 2,509,319 parameters, 0 gradients, 5.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\всякая хуйня Игната\\SkyVision\\test\\labels.cache... 1579 images, 124 backgrounds, 0 corrupt: 100%|██████████| 1579/1579 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\  \\SkyVision\\test\\images\\2664_jpg.rf.e165d9af80c1d4d370593d2b5b5fa34b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\  \\SkyVision\\test\\images\\Kharkiv_2022_A_1_R1C6_2000_2500_5000_5500_jpg.rf.416898acb3bcccea2602a36beed5b08e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\  \\SkyVision\\test\\images\\Tripoli_2022_R3C2_1000_1500_13500_14000_jpg.rf.4a303c5c4fabd5987b3701fe35c81e92.jpg: 5 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 99/99 [03:21<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1579      13715      0.814      0.611      0.725      0.584\n",
      "              building        884      12393      0.817      0.389      0.601      0.408\n",
      "                 field        421        566       0.88      0.753      0.846      0.753\n",
      "                forest        371        446       0.95       0.76       0.86      0.743\n",
      "                  lake        107        201       0.68      0.592      0.643      0.505\n",
      "                  road         94        109      0.744       0.56      0.674      0.514\n",
      "Speed: 1.4ms preprocess, 103.6ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val4\u001b[0m\n",
      "📊 Результаты оценки:\n",
      "mAP50: 0.725\n"
     ]
    }
   ],
   "source": [
    "# Валидация на тестовых данных\n",
    "results = model.val(\n",
    "    data='data.yaml',\n",
    "    split='test',    # используем ТЕСТОВЫЕ данные\n",
    "    conf=0.25, # уровень достоверности\n",
    "    iou=0.3, #максимальный порог пересечения объектов\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "print(f\"📊 Результаты оценки:\")\n",
    "print(f\"mAP50: {results.box.map50:.3f}\")\n",
    "\n",
    "# print(results.box)\n",
    "\n",
    "# Если mAP50 < 0.6 → нужно улучшать модель\n",
    "# Если mAP50 > 0.8 → отличный результат!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9189a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Моделюси/test_yolov12n_gpu_1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab90c6d",
   "metadata": {},
   "source": [
    "Тесты моделей:\n",
    "\n",
    "cpu yolov10n - p: 1        r: 0.5       map50: 0.75       map50-95: 0.56\n",
    "\n",
    "gpu yolob12n - p:0.81   r:0.61  map50:72    map50-95:0.58   103.6ms inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875c15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 buildings, 20.0ms\n",
      "Speed: 17.0ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "⏱️ Время обработки одной фотографии: 0.361 секунд\n"
     ]
    }
   ],
   "source": [
    "# Тест рандом изображени\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "model = YOLO('Моделюси/test_yolov12n_gpu_1.pt')\n",
    "\n",
    "# Загружаем изображение\n",
    "image_path = 'Моделюси/just_Ignat.PNG'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Замер времени для одного предсказания\n",
    "start_time = time.time()\n",
    "results = model.predict(image)  # или model.predict(image)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"⏱️ Время обработки одной фотографии: {end_time - start_time:.3f} секунд\")\n",
    "\n",
    "# Показать результаты\n",
    "for r in results:\n",
    "    im_array = r.plot()  # рисуем bbox на изображении\n",
    "    cv2.imshow('Result', im_array)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "199f2728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Обрабатываем изображение...\n",
      "\n",
      "image 1/1 d:\\  \\SkyVision\\\\image.PNG: 512x640 (no detections), 47.0ms\n",
      "Speed: 3.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "⏱️ Время обработки: 0.133 секунд\n",
      "💾 Результат сохранен: Моделюси\\image_result.jpg\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "model = YOLO('Моделюси/test_yolov12n_gpu_1.pt')\n",
    "image_path = 'Моделюси/image.PNG'\n",
    "\n",
    "print(\"🚀 Обрабатываем изображение...\")\n",
    "start_time = time.time()\n",
    "\n",
    "results = model(image_path)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"⏱️ Время обработки: {end_time - start_time:.3f} секунд\")\n",
    "\n",
    "# Сохраняем результат в ту же папку\n",
    "output_dir = os.path.dirname(image_path)  # получаем путь к папке\n",
    "output_path = os.path.join(output_dir, 'image_result.jpg')\n",
    "\n",
    "# Сохраняем изображение с детекциями\n",
    "for r in results:\n",
    "    r.save(filename=output_path)\n",
    "\n",
    "print(f\"💾 Результат сохранен: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76589f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import cv2\n",
    "for r in results:\n",
    "    im_array = r.plot()  # рисуем bbox на изображении\n",
    "    cv2.imshow('Result', im_array)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
