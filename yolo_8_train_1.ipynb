{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c44b92",
   "metadata": {},
   "source": [
    "# Тестики пестики #\n",
    "Тестовая модель Ёлё8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a35440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\всякая хуйня Игната\\SkyVision\\new_yolo_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashAttention is not available on this device. Using scaled_dot_product_attention instead.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bab4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n-seg.yaml')\n",
    "\n",
    "# n - минимкум\n",
    "# s\n",
    "# m\n",
    "# l\n",
    "# x = максимум"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410ca9b",
   "metadata": {},
   "source": [
    "Смотрим доступно ли CPU\n",
    "\n",
    "Если нет, то нужно бут при обучении поставить device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c5ee3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9604ddf",
   "metadata": {},
   "source": [
    "__Тутор че выбрать при каком железняке__\n",
    "\n",
    "* batch (количество батчей)\n",
    "    * cpu: 2-4\n",
    "    * 8gb: 8-16\n",
    "    * 12gb: 16-24\n",
    "\n",
    "* workers\n",
    "    * cpu: 1(\n",
    "    * 8gb: 4-6\n",
    "    * 12gb: 6-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "300327b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.218 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.63  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.yaml, data=data.yaml, epochs=20, time=None, patience=15, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=2, project=None, name=yolov8n_gpu_simple_1, exist_ok=True, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.005, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.1, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\segment\\yolov8n_gpu_simple_1\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1005250  ultralytics.nn.modules.head.Segment          [6, 32, 64, [64, 128, 256]]   \n",
      "YOLOv8n-seg summary: 261 layers, 3,264,786 parameters, 3,264,770 gradients, 11.5 GFLOPs\n",
      "\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1650 GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\всякая хуйня Игната\\SkyVision\\train\\labels... 15612 images, 920 backgrounds, 0 corrupt: 100%|██████████| 15612/15612 [01:04<00:00, 240.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\2066_jpg.rf.8f076a7436af9b8965a29ee2c70173c9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\2066_jpg.rf.e39c8475a83e2b097294bdb11c6b60e3.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\7277_jpg.rf.3491f767bd90d1c878806ae89cda07cd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\7277_jpg.rf.6f3233ffbe7fe994914f09ce509657dc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Kharkiv_2022_A_1_R1C5_10000_10500_3500_4000_jpg.rf.633047caf71fc13a205649024ab5ff0e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Kharkiv_2022_A_1_R1C5_11500_12000_5000_5500_jpg.rf.b97a7be0164294c358af94b1850c06d6.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_1000_1500_2000_2500_jpg.rf.844984fc01e8e5ff754bdacb89aa5063.jpg: 11 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_1000_1500_7000_7500_jpg.rf.cb19ace54fa7d037ec4f2b88cf1a277c.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_1000_1500_9000_9500_jpg.rf.8f4afb07362b9eabb114b8fa6f59a7cc.jpg: 12 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_1000_1500_9500_10000_jpg.rf.ca836179a40f9c3bb7c8b3ca57122d37.jpg: 12 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_R3C2_10500_11000_11500_12000_jpg.rf.33a1072ad36cf872a299bcaa64a158d4.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\  \\SkyVision\\train\\images\\Tripoli_2022_V2_R2C4_500_1000_12000_12500_jpg.rf.97a02ca5ecf1e30556acb18233319dcb.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\  \\SkyVision\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\всякая хуйня Игната\\SkyVision\\valid\\labels... 3154 images, 215 backgrounds, 0 corrupt: 100%|██████████| 3154/3154 [00:13<00:00, 227.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\  \\SkyVision\\valid\\images\\2318_jpg.rf.b6a36269cb2eeac0825210a49cb326c1.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\  \\SkyVision\\valid\\labels.cache\n",
      "Plotting labels to runs\\segment\\yolov8n_gpu_simple_1\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.005, momentum=0.937) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns\\segment\\yolov8n_gpu_simple_1\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      3.42G      2.118      3.493      2.754      2.398          5        640: 100%|██████████| 7806/7806 [19:06<00:00,  6.81it/s] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [01:45<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.496       0.27      0.245      0.177       0.49      0.269      0.235      0.163\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      3.09G      1.515      2.748      2.017      1.724          8        640: 100%|██████████| 7806/7806 [17:22<00:00,  7.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [13:07<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.462      0.347      0.367      0.227      0.453      0.345       0.35      0.228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      3.12G      1.398      2.557      1.808      1.606         22        640: 100%|██████████| 7806/7806 [17:17<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [06:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.425      0.483        0.4      0.252      0.412      0.455      0.381      0.247\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      2.89G      1.327      2.426      1.686      1.543         15        640: 100%|██████████| 7806/7806 [17:14<00:00,  7.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [10:45<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.434       0.51      0.406      0.271      0.435      0.497       0.42      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      3.45G      1.268       2.33      1.603        1.5         57        640: 100%|██████████| 7806/7806 [17:16<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [09:14<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.463      0.538      0.465      0.287      0.462       0.52      0.461      0.289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      2.78G      1.232       2.28      1.535      1.466         34        640: 100%|██████████| 7806/7806 [17:15<00:00,  7.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [08:15<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.553       0.56      0.545      0.348       0.55      0.551       0.53      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      3.39G      1.209      2.231      1.499      1.443         34        640: 100%|██████████| 7806/7806 [16:26<00:00,  7.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [07:15<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.486      0.587      0.515      0.338      0.485      0.571      0.513      0.338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      2.59G      1.175      2.165      1.442      1.419         34        640: 100%|██████████| 7806/7806 [16:11<00:00,  8.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [05:10<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.522      0.578      0.544      0.365      0.521      0.569      0.535      0.362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      3.55G      1.154      2.135      1.397      1.405         20        640: 100%|██████████| 7806/7806 [16:12<00:00,  8.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [06:41<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938       0.57      0.585      0.537      0.363      0.584      0.564       0.53       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      3.49G       1.13      2.108      1.355      1.386         30        640: 100%|██████████| 7806/7806 [16:14<00:00,  8.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [05:26<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.572      0.616      0.552      0.379      0.571      0.602      0.553      0.378\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      2.99G      1.132      2.133      1.487      1.491         12        640: 100%|██████████| 7806/7806 [16:09<00:00,  8.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [05:54<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.575      0.569       0.56      0.381      0.579      0.564      0.559      0.381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20       1.8G      1.098      2.047      1.379       1.46         13        640: 100%|██████████| 7806/7806 [15:47<00:00,  8.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [03:39<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.557      0.605      0.548       0.39      0.554      0.599      0.551      0.387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      3.28G       1.08      2.005      1.341      1.438        111        640: 100%|██████████| 7806/7806 [15:50<00:00,  8.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [01:21<00:00,  9.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.572      0.599      0.567      0.396      0.578      0.579      0.558      0.388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      2.46G      1.057      1.944      1.283       1.42         13        640: 100%|██████████| 7806/7806 [15:47<00:00,  8.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [03:53<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.555      0.631       0.56      0.389      0.548      0.614      0.556      0.387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      3.11G      1.036       1.92      1.235      1.407          4        640: 100%|██████████| 7806/7806 [15:46<00:00,  8.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [03:32<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.571      0.642      0.572      0.413      0.571      0.629      0.567      0.401\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      3.32G      1.015      1.882      1.222      1.383          9        640: 100%|██████████| 7806/7806 [15:49<00:00,  8.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [05:02<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.566      0.629       0.56      0.402      0.564      0.618      0.554      0.387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      3.32G     0.9964      1.834      1.167      1.366         40        640: 100%|██████████| 7806/7806 [15:49<00:00,  8.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [05:21<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.599      0.649       0.59      0.426      0.595      0.633      0.585      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      2.84G     0.9791      1.807      1.134      1.352          3        640: 100%|██████████| 7806/7806 [15:45<00:00,  8.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [04:35<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.581      0.668        0.6      0.435      0.576      0.651      0.586      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20       3.4G     0.9608      1.768        1.1      1.332          2        640: 100%|██████████| 7806/7806 [15:47<00:00,  8.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [04:45<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.591       0.67      0.612      0.453      0.594      0.645      0.603      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20         5G     0.9413      1.743      1.063      1.318         31        640: 100%|██████████| 7806/7806 [49:20<00:00,  2.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [11:02<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.616      0.673      0.631      0.464      0.614      0.652      0.625      0.443\n",
      "\n",
      "20 epochs completed in 8.116 hours.\n",
      "Optimizer stripped from runs\\segment\\yolov8n_gpu_simple_1\\weights\\last.pt, 6.8MB\n",
      "Optimizer stripped from runs\\segment\\yolov8n_gpu_simple_1\\weights\\best.pt, 6.8MB\n",
      "\n",
      "Validating runs\\segment\\yolov8n_gpu_simple_1\\weights\\best.pt...\n",
      "Ultralytics 8.3.63  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3,259,234 parameters, 0 gradients, 11.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 789/789 [01:09<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3154      28938      0.617      0.672      0.631      0.464      0.614      0.652      0.625      0.443\n",
      "              building       1797      26357      0.773      0.435      0.596      0.359       0.78      0.422      0.581      0.301\n",
      "                 field        797       1049      0.805      0.781      0.846      0.723      0.804      0.769      0.825      0.681\n",
      "                forest        724        911       0.88      0.717      0.828      0.676      0.885      0.714      0.828      0.682\n",
      "                  lake        203        358        0.7      0.642      0.705      0.544      0.696      0.632      0.694      0.542\n",
      "                  road        195        226      0.492      0.673      0.597      0.414      0.465      0.619      0.546       0.37\n",
      "                 zrail         32         37     0.0533      0.784      0.216     0.0647     0.0524      0.757      0.277     0.0819\n",
      "Speed: 0.5ms preprocess, 10.5ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\segment\\yolov8n_gpu_simple_1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=20,          # Эпохи\n",
    "    \n",
    "    imgsz=640, # Размер изображеньки ставим 640, т.к. в этом формате размечаем\n",
    "    \n",
    "    batch=2,            # По скок изображенек берем за прогон\n",
    "    \n",
    "    patience=15,    #Терпение, хз че это значит ?\n",
    "\n",
    "    device='cuda',      # Используем CPU, если нет видеокарты, если есть, то ставим 'cuda'\n",
    "\n",
    "    workers=2,          # Минимум workers\n",
    "    \n",
    "    lr0=0.005,   # Лернинг рэйт ?\n",
    "\n",
    "    optimizer='Adam',   # Adam - легкий оптимизатор, AdamW - Жестче\n",
    "\n",
    "    # weight_decay = 0.0005,   # Регуляризация ?\n",
    "    \n",
    "    name='yolov8n_gpu_simple_1',\n",
    "    \n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762692e5",
   "metadata": {},
   "source": [
    "Тестим че получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dec57047",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'runs/segment/yolov8n_gpu_simple_1/weights/best.pt'\n",
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26378980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классы: {0: 'building', 1: 'field', 2: 'forest', 3: 'lake', 4: 'road', 5: 'zrail'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Классы: {model.names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7fc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05fe8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('runs/detect/train/results.png'):\n",
    "    display(Image(filename='runs/detect/train/results.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28ea4ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.63  Python-3.11.9 torch-2.5.1+cu121 CPU (AMD Ryzen 5 2600 Six-Core Processor)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3,259,234 parameters, 0 gradients, 11.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\всякая хуйня Игната\\SkyVision\\test\\labels... 1602 images, 124 backgrounds, 0 corrupt: 100%|██████████| 1602/1602 [00:10<00:00, 149.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\  \\SkyVision\\test\\images\\2664_jpg.rf.e165d9af80c1d4d370593d2b5b5fa34b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\  \\SkyVision\\test\\images\\Kharkiv_2022_A_1_R1C6_2000_2500_5000_5500_jpg.rf.416898acb3bcccea2602a36beed5b08e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\  \\SkyVision\\test\\images\\Tripoli_2022_R3C2_1000_1500_13500_14000_jpg.rf.4a303c5c4fabd5987b3701fe35c81e92.jpg: 5 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\  \\SkyVision\\test\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [03:26<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1602      13785      0.716       0.67      0.703      0.535       0.71      0.683      0.741      0.536\n",
      "              building        885      12398      0.804      0.469       0.64      0.431      0.797      0.464      0.635      0.381\n",
      "                 field        421        566      0.869      0.797      0.868      0.766      0.842      0.772      0.845      0.746\n",
      "                forest        386        475      0.937      0.747      0.853      0.746      0.937      0.747      0.853      0.757\n",
      "                  lake        107        201      0.766      0.637      0.728      0.611      0.784      0.652       0.75      0.635\n",
      "                  road        107        122      0.748      0.631      0.749      0.564      0.699       0.59      0.705       0.53\n",
      "                 zrail         23         23      0.172      0.739      0.382     0.0935      0.202       0.87       0.66      0.166\n",
      "Speed: 1.5ms preprocess, 111.5ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\segment\\val\u001b[0m\n",
      "📊 Результаты оценки:\n",
      "mAP50: 0.703\n"
     ]
    }
   ],
   "source": [
    "# Валидация на тестовых данных\n",
    "results = model.val(\n",
    "    data='data.yaml',\n",
    "    split='test',    # используем ТЕСТОВЫЕ данные\n",
    "    conf=0.25, # уровень достоверности\n",
    "    iou=0.3, #максимальный порог пересечения объектов\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "print(f\"📊 Результаты оценки:\")\n",
    "print(f\"mAP50: {results.box.map50:.3f}\")\n",
    "\n",
    "# print(results.box)\n",
    "\n",
    "# Если mAP50 < 0.6 → нужно улучшать модель\n",
    "# Если mAP50 > 0.8 → отличный результат!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9189a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Моделюси/yolov8n_gpu_simple_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875c15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 buildings, 20.0ms\n",
      "Speed: 17.0ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "⏱️ Время обработки одной фотографии: 0.361 секунд\n"
     ]
    }
   ],
   "source": [
    "# Тест рандом изображени\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "model = YOLO('Моделюси/yolov8n_gpu_simple_1')\n",
    "\n",
    "# Загружаем изображение\n",
    "image_path = 'Моделюси/just_Ignat.PNG'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Замер времени для одного предсказания\n",
    "start_time = time.time()\n",
    "results = model.predict(image)  # или model.predict(image)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"⏱️ Время обработки одной фотографии: {end_time - start_time:.3f} секунд\")\n",
    "\n",
    "# Показать результаты\n",
    "for r in results:\n",
    "    im_array = r.plot()  # рисуем bbox на изображении\n",
    "    cv2.imshow('Result', im_array)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199f2728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\всякая хуйня Игната\\SkyVision\\new_yolo_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashAttention is not available on this device. Using scaled_dot_product_attention instead.\n",
      "🚀 Обрабатываем изображение...\n",
      "\n",
      "image 1/1 d:\\  \\SkyVision\\\\img_input\\image.PNG: 640x608 5 buildings, 1 road, 58.1ms\n",
      "Speed: 37.0ms preprocess, 58.1ms inference, 104.1ms postprocess per image at shape (1, 3, 640, 608)\n",
      "⏱️ Время обработки: 1.720 секунд\n",
      "💾 Результат сохранен: Моделюси/img_input\\image_result_5.jpg\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "model = YOLO('Моделюси/yolov8n_gpu_simple_1.pt')\n",
    "image_path = 'Моделюси/img_input/image.PNG'\n",
    "\n",
    "print(\"🚀 Обрабатываем изображение...\")\n",
    "start_time = time.time()\n",
    "\n",
    "results = model(image_path, conf=0.2)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"⏱️ Время обработки: {end_time - start_time:.3f} секунд\")\n",
    "\n",
    "# Сохраняем результат в ту же папку\n",
    "output_dir = os.path.dirname(image_path)  # получаем путь к папке\n",
    "output_path = os.path.join(output_dir, 'image_result_5.jpg')\n",
    "\n",
    "# Сохраняем изображение с детекциями\n",
    "for r in results:\n",
    "    r.save(filename=output_path)\n",
    "\n",
    "print(f\"💾 Результат сохранен: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76589f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import cv2\n",
    "for r in results:\n",
    "    im_array = r.plot()  # рисуем bbox на изображении\n",
    "    cv2.imshow('Result', im_array)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
